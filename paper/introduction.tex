\section{Introduction}
\label{sec:introduction}

It is well-known that network configuration is highly error
prone and that such errors can lead to costly network
downtime~\cite{mahajan+:bgp-misconfiguration,feamster+:rcc,batfish}.
For instance, a recent misconfiguration led to an hour-long, nation-wide outage for Time Warner's backbone network~\cite{time-warner}; and a major BGP-related incident makes international news every few months~\cite{bgpmon}.

%For instance, in the context of BGP, Mahajan~~\cite{mahajan+:bgp-misconfiguration}
%estimated that 200-1200 prefixes suffered from
%misconfiguration each day and that close to 3 in 4 of all
%new prefix advertisements were the result of misconfiguration.
%Moreover, these misconfigurations sometimes cause significant network downtime for
%individual networks~\cite{time-warner} or even broader internet connectivity problems~\cite{routing-instability,mahajan+:bgp-misconfiguration}.
%\dpw{Note that \cite{time-warner} and I am not sure about the specifics of the problem there
%or what exactly was misconfigured.  It is also unclear if our language really helps with the
%``broader internet connectivity problems'' however, I thought that adding some specific examples
%would help make the intro more compelling.  Feel free to rewrite.}

One reason for network configuration being onerous is that device configuration languages are low-level and several configuration elements must be kept consistent (e.g., interface addresses) for the device to behave as intended.

Another, more fundamental reason is the semantic mismatch between the intended high-level
policies and the low-level device-by-device configurations.  In particular,
many policies involve network-wide properties---prefer a certain neighbor,
never announce a particular destination externally,
use a particular path only if another fails---but configurations describe the behavior of
individual devices.
%
Operators must manually decompose network-wide policy into device-level behaviors, such that their interactions satisfy the high-level objectives.
%
Ensuring policy-compliance through this manual decomposition is challenging under normal
circumstances and even more so in the face of failures. Some decompositions that work correctly
in failure-free environments, violate key constraints when failures occur.
%
As a result, many network configuration problems are only revealed after failures~\cite{batfish},
sometimes making a bad situation worse.

To reduce configuration errors, many practitioners have a adopted a template-based
approach~\cite{hatch,thwack}, in which common configuration patterns are captured as parameterized templates.  More powerful still are systems like
ConfigAssure~\cite{narain:lisa05,narain+:configassure}, which use SAT solving
and model finding tools to fill in parameters in configurations while
ensuring key correctness constraints are satisfied.  However,
 while templates help ensure certain kinds of consistency across devices, 
they do not bridge the
semantic divide between network policies and device-level configuration,
nor do they do not provide fundamentally different abstractions
from existing configuration languages or new, higher-level reasoning 
principles.

Software-defined networking (SDN) and its abstractions 
are, in part, the research
community's response to the difficulty of maintaining policy
compliance through distributed interaction of individual
devices~\cite{sdn-languages}. Indeed, instead of organizing networks
around a distributed collection of devices that compute forwarding tables through
mutual interactions, the devices are told how to
forward packets by a centralized controller. The controller is responsible for ensuring that the
paths taken are compliant with operator specifications.
%Researchers
%have developed increasingly sophisticated languages that let operators
%specify desirable network paths~\cite{x,y,z} which are then translated
%to forwarding tables at runtime.

The centralized control planes of SDN, however, are not a panacea.
First, while many SDN systems provide effective \emph{intra}-domain routing
abstractions, allowing users to specify paths within their own network,
they fail to provide a coherent means to enable specification of preferred
\emph{inter}-domain routes.  Second, centralized control planes
require careful design and engineering to be robust to failures at scale---one must ensure that all devices can communicate with the controller at all times, even under arbitrary combinations of failure. Even ignoring failures, it is necessary for controller systems to
scale to meet the demands of larger, geographically distributed networks, 
and to react sufficiently quickly
to a changing environment. To address this challenge, some researchers are beginning to 
explore
multi-controller networks, with interacting controllers, thus bringing back distributed
control planes~\cite{mccauley2013extending,onos} and their current programming difficulties.  
%However, academic
%language design and implementation efforts have not kept pace.  For instance, work on many
%experimental SDN languages~\cite{frenetic,flowlog,vericon,merlin,netkat,kinetic,pga} has not yet shown how to implement fault tolerant
%multi-controller systems that support their high-level abstractions efficiently.

Hence, in this paper, we have two central goals:
\begin{enumerate}
\item Design a new, high-leve language with abstractions 
for expressing intra-domain routing, inter-domain 
routing and routing alternatives in case of failures.
\item Define algorithms for compiling these specifications in to 
configurations for devices running standard
distributed control plane algorithms, while ensuring correct behavior
independent of the number of faults.
\end{enumerate}

To achieve the first goal, we borrowed heavily from the design of
recent high-level SDN languages such as FatTire~\cite{fattire}, 
Merlin~\cite{foster:merlin}, and
NetKAT~\cite{netkat} by using regular expressions to specify paths
through networks.  However, our design also contains several key
differences from existing languages.  The most important difference is semantic:  the paths specified
by programmers can extend from outside the operator's network to inside
the network, across several devices internally, and then out again.  This design
choice allows users to specify preferences about both external and internal 
routes in the same uniform notation.  No SDN programming language provides
similar facilities.  In addition,
we incorporate expression of user preferences in to the algebra
of regular expressions and provide a semantics to our language
in terms of sets of ranked paths.  These preferences indicate possible
fail-over routes:  If too many faults occur, the network may be
disconnected, but as long as any path the user has expressed is
still available, the system guarantees the highest-ranked, available
path will be taken.  We also support network operators by defining a
set of common abbreviations for entering, leaving, and traversing
the user network and we provide abstractions for managing common features of
control plane algorithms such as route aggregation.  Operators use familiar logical operations
to build routes in a modular and compositional manner from these 
primitives.  Our abbreviations are translated in to our regular-expression-based
intermediate representation and compiled from there.

To achieve the second goal, we define program analysis and compilation
algorithms that translate the regular policies in to a graph-based
intermediate language and from there in to BGP.  During the
compilation process, our compiler automatically synthesizes per-device
import and export filters, local preferences, MED attributes, and 
community tags.  We chose BGP for pragmatic reasons:  it is an industry
standard and many data centers use it internally as well as externally.
Indeed, despite the presence of SDN, many networks will continue to
use BGP for the foreseeable future due to investments they have already
made in the infrastructure, the difficulty of transitioning to SDN,
and the scalability and fault-tolerance advantages of a distributed
control plane.  However, using BGP as a back end is not without its 
challenges: not all high-level specifications can be implemented correctly in
the presence of arbitrary failures.  Consequently, we define new
program analysis algorithms to detect specifications that cannot be implemented
and report our findings to the user, so he or she may fix the specification
early rather than waiting until configurations have been deployed.  We also
analyze route aggregation to detect the possibility of failure-induced black-holes.
These algorithms differ from
standard BGP analysis algorithms~\cite{feamster:rcc,batfish} because they operate on 
our graph-based intermediate representation, which operates at a higher level
of abstraction than raw BGP configurations (and which has the pleasant effect of simplifying our 
task).

To evaluate the \sysname{} language and system, we have experimented with specifying policy
for several realistic data center and backbone networks and compared these specifications
with existing configurations. We have also
measured the performance of our compiler, demonstrating that our compilation
algorithms scale to topologies with several thousand routers.

\dpw{The following could be cut for space.}
In the remainder of the paper, we review BGP (Section~\ref{sec:background}---readers
familiar with BGP may skip this section),
further motivate the need for new languages 
for programming distributed control planes (Section \ref{sec:motivation}),
introduce \sysname{} by example (Section \ref{sec:propane}), 
explain our compiler algorithms (Section \ref{sec:compilation}),
present several lemmas justifying the correctness of our techniques (Section \ref{sec:theory}), describe our implementation (Section \ref{sec:implementation})
evaluate our work  (Section \ref{sec:evaluation}) and discuss related work (Section \ref{sec:related}).

%% In this paper, we ask if it is possible to program 
%% fully distributed control planes using 
%% \emph{end-to-end}, 
%% \emph{network-wide} policies, while handing the job of compiling
%% such policy.  In particular,
%% operators should be able to directly express \emph{end-to-end}, 
%% \emph{network-wide} policies directly; it is the job of a compiler
%% to decompose such policies into individual device configurations. 
%% In addition, the resulting forwarding behavior, which emerges through device interactions, must be policy-compliant under all possible failures.
%% If successful, this approach would combine easy programmability of centralized control planes with the failure robustness and scalability of distributed control planes.
%% %
%% More pragmatically, it would help many networks that, for the foreseeable future, will continue to use a distributed control plane, due to the difficulty of migrating to SDN or the inherent scalability and failure-robustness of distributed control.

%% Through \sysname, our system that includes a language and a compiler, we demonstrate the feasibility of programming distributed control planes. We focus on BGP, a common and highly flexible way to implement distributed control planes, and show how to automatically generate router BGP configurations from network-wide policies.

%% We face two challenges in designing \sysname that differ from designing a system for programming data planes~\cite{x,y,z}. The first is policy specification itself---specifying network {\em policies} is different from specifying network {\em paths}.
%% %
%% The specification must compactly capture behavior under all possible failures. Since there is no controller at runtime, the routers must be programmed ahead of time, based on the specification, to handle failures.
%% %
%% Further, many policies naturally under-specify paths (e.g., "prefer paying neighbors" is not a concrete path).
%% %
%% \sysname addresses this specification challenge by allowing operators to express {\em path preferences}, where preference describes a set of valid paths and less-preferred options are taken only when a higher-preference options are unavailable.

%% The direct nature of \sysname specifications brings up the second challenge, of compiling them to router configurations.  We must compute the sets of paths represented by the intersection of multiple preferences and topology, compute which ones can be honored under a given failure scenario, and ensure policy compliance under all possible failure cases. We handle this challenge by compactly capturing policy and topology in a {\em product graph} and developing efficient algorithms that operate on this graph.

%% We evaluate \sysname by using it to encode policies of real backbone and data center networks.

%% \todo{new intro is not complete}



Shepherd letter:

Here are the most important changes (which are all "must changes"):

- title, abstract, and introduction (and throughout the paper): tone down the contributions and make sure it is clear this paper is about BGP (which is fine... BGP is the currently (and only) default protocol in large-scale Data-Centers. In other contexts, such as Internet Service Providers (ISPs), BGP is not the only protocol but by far the hardest to configure. The ability to automate its configuration is therefore useful.)

- In places where you feel can say more than just about BGP make an explicit remark and explain clearly how you would generalise the results.

- Section on template generation: please improve the explanations (see reviews).

- Theorem 7.2 - make clear what the proof covers and improve proof.



===========================================================================
                           PLDI '17 Review #187A
---------------------------------------------------------------------------
   Paper #187: Network Configuration Synthesis with Abstract Topologies
---------------------------------------------------------------------------

                 Reviewer expertise: Y. Knowledgeable
                      Overall merit: B. OK paper, but I will not champion
                                        it

                           ===== Strengths =====

- the problem of synthesizing control plane configurations is important and well motivated
- the insight of synthesizing templates for the different roles of routers is great
- extensive evaluation

                          ===== Weaknesses =====

- presentation is difficult to follow
- the approach is specific to BGP, and it uses the protocol in a certain way
- the required input from the user might be difficult to provide

                      ===== Comments to authors =====

The paper addresses the problem of synthesizing configurations of
routers that participate in the BGP protocol. The authors claim
that existing synthesis techniques are not adopted by network
operators since they do not synthesize uniform configurations for
routers with similar roles.

To address this issue, the paper suggests to divide routers based
on their roles, and to automatically synthesize templates for these
roles. Technically, instead of working at the level of the concrete
topology, the paper considers abstract topologies where routers are
grouped into abstract nodes based on their roles.

Roughly speaking, abstract topologies are an existential
abstraction of concrete ones (i.e., abstract nodes are connected by
an edge if some concrete nodes that they represent are connected by
a concrete edge). This abstraction is refined with constraints that
restrict the edges in concretizations. The abstract topology
including the constraints are provided by the user.

The generated templates are correct for every concretization of the
abstract topology. The considered policies include routing
constraints (that are translated to regular expressions) as well as
fault tolerance constraints. The most interesting part of the
proposed technique is the way in which fault tolerance is ensured.
The authors suggest several inference rule for inferring
information on the existence of edge disjoint paths in the network
(that also satisfy the routing constraints -- this is achieved by
performing the analysis on a product graph of the DFAs of the
routing constraints and the topology). Their fault tolerance
analysis then iteratively applies these rules. Once the analysis is
complete, templates are generated.

Comments:
---------

The paper addresses an important problem and takes a really nice
approach for solving it. Synthesizing templates for roles is a
great idea. I was very excited to read this paper. The evaluation
of the approach is also extensive and shows promise. But despite my
enthusiasm, I found the presentation of the paper lacking.

The technical details of the paper were at times difficult to
understand. In addition, some of the concepts used are related to
existing concepts, but these relations are not mentioned nor
explained. Below are some concrete examples.

One of the contributions listed by the authors is the notion of
abstract topologies. Topology abstractions for BGP were also
defined in the following paper:

Adi Sosnovich, Orna Grumberg, Gabi Nakibly: Analyzing Internet
Routing Security Using Model Checking. LPAR 2015: 112-129

The abstractions there are quite different, but some discussion is
appropriate.

In particular, the notion of abstract topology is based on an
existential abstraction which is a classical notion, and it would
be good to relate the two.

The product graph construction is also very similar to standard
constructions used in the automata-theoretic approach to
verification.

Providing an abstract topology that is ``precise'' enough is
tedious. The user has to provide invariants on the structure of the
underlying concrete topology. Is this a reasonable requirement from
a network operator?

In page 4, the role of the template variables is not explained. In
addition, the TG, TL, N1 and N2 are what you later call locations,
right? these are the abstract nodes of the topology. These
connections are not explained explicitly, which make the paper
difficult to follow.

In page 5, PG is used in two different meanings: once as part of
the policy, and later as the acronym for product graph. This is
extremely confusing. In general, less acronyms would help. In
addition, the use of PG in the policy could use further
explanation. Why isn't it $PG?

In page 5, please clarify what you mean by soundness. I assume that
you mean that every inferred fact is correct for every
concretization of the abstract topology.

fig 5: please add "l" to the figure.

page 5 "for each predicate matching traffic" -- what are those?

page 6: you suddenly mention E which was defined in a completely
different section all the way back in page 3. Please clarify that
this is simply an edge of the topology.

page 8: I did not understand how \nu Z is used. It would help to
first explain what you are trying to find. You say that you
minimize j and k. Don't you want to maximize them?

Template generation: if I understand correctly, you add tags to the
BGP announcements. Is this acceptable by network operators? Doesn't
it affect the protocol? It seems that you in fact change the
protocol (or refine it). In addition, this raises a question
regarding the generality of the approach. Can a variant be used
with different protocols?

This section was especially difficult for me to understand. For
example:

page 9 "If we determine that each router..." -- what happens if you
don't?

The part about instantiating the templates (explained in page 3) is
under-explained in the paper. A lot of it is deferred to the
appendix (as mentioned after theorem 7.2). I believe a better
explanation should be included in the paper.

Regarding the paragraph on "incrementality" -- please clarify
whether these optimizations are manual (my understanding is that
they are).

Implementation "inference rules... depend only on the topology" --
then why didn't you present them this way? This is confusing since
earlier you explained that it is important to perform the inference
on the product graph that also includes routing information.

typo:

- p3 "template has... and are..."

===========================================================================
                           PLDI '17 Review #187B
---------------------------------------------------------------------------
   Paper #187: Network Configuration Synthesis with Abstract Topologies
---------------------------------------------------------------------------

                 Reviewer expertise: X. Expert
                      Overall merit: A. Good paper, I will champion it

                           ===== Strengths =====

- very relevant practical problem

- interesting insights on how to reason about fault-tolerance at an abstract level (could spur further research in this area)

- working system that generates actual router configuration (Quagga-based by default)

                          ===== Weaknesses =====

- expressiveness and resilience analysis is rather coarse-grained: no bound is given/discussed and the evaluation only presents binary information (precise/conservative)

- lack of details regarding configuration evolvability/incrementality

                      ===== Comments to authors =====

I really enjoyed the paper and I would like to see it accepted. The problem is very relevant, both practically (the insight of working at the template level closely matches operators’ practice while enabling the synthesis engine to scale much better) and theoretically (inferences rules to reason about failures at the abstract level). The solutions proposed are promising and novel. While Methane and Propane (its closest competitor, published at SIGCOMM’16) share common themes (the policy languages, in particular, are quite close), Methane does provide significant benefits with respect to Propane in terms of abstract reasoning.

On the minus side, while the paper builds a compelling argument regarding configuration evolvability, I found the paper quite thin on that front. Based on the elements provided, it is hard to assess that any changes to the concrete topology is guaranteed to cause local changes only. It is not a show-stopper though as the rest of the paper contributions are significant enough.

Methane has been implemented and generates actual router configurations (expressed in the Quagga language). The evaluation is good even though some points could be perfected (see below).

Below are a few questions I’d like the authors to answer:

* As far as I can tell, Methane fault-tolerance policies and inference rules are restricted to link failures, not node failures which, although less likely, do still happen quite often in large-scale networks. Do the inference rules and facts generalize to node-disjointness? If so how, if not why?

* How far away from the real value can the lower bound computed by the inference rules be? Can you bound it somehow? In general, I think it would help the reader to illustrate a situation in which Methane’s inferred lower-bound is conservative instead of being precise, e.g. could be the case that you mention in Section 9.1.

* I think the paper is quite thin on incrementality. While the intuition presented in Section 7 is nice (I see a parallel with source routing in which the rules in the core of the network are fixed and where the tagging is moved to the edge), it seems hard to believe that prefix template variable is the only piece that requires to be changed upon change in the concrete topology. If that's the case, it requires more backing on why it is the case.

* Another point regarding incrementality. Would you also have it considering other protocols? In particular, my intuition is that incrementality is possible in your case because you’re considering neighbor & policy-based configurations. This wouldn’t be true for say, link-state protocols where I would expect that more network-wide changes are required to implement a requirement (e.g., weight changes in multiple locations).

* How far off was Methane when it generated conservative bound instead of precise ones? The Evaluation only gives binary information right now. Please add these numbers to the paper. Also, and this goes back to my point above, the fact that you start to have conservative results instead of precise ones when switching from valley-free routing to shortest-path routing makes the reader wonder how would the result change should you use more complex routing policies. This goes back to my point above > Please comment on what Methane precision depends on.

* AFAIU, you used a fat tree topology for the ISP topology, which is not so realistic IMHO.  Would the results be any different should you use a (much less regular) topology from topology-zoo or RocketFuel instead? Please justify why/why not?

* Related work on the connectivity guarantees provided by policy-based routing protocols exists, in particular “A Theory for the Connectivity Discovered by Routing Protocols” (TON 2012) by Sobrinho and Quelhas. In this paper, the authors provide a “polynomial time algorithm to compute the minimum number of links whose failure leaves a route-vector protocol without a communication path from one given node to another”. As it relates to Methane reasoning on policy-compliant connectivity (arguably on abstract, not concrete topologies), I would still cite it and distinguish from it.

### Nits:

- blackhoes > blackholes.
- It would be nice to have a legend in Figure 4 describing what TL, TG, AL,  G, and S are.

===========================================================================
                           PLDI '17 Review #187C
---------------------------------------------------------------------------
   Paper #187: Network Configuration Synthesis with Abstract Topologies
---------------------------------------------------------------------------

                 Reviewer expertise: Y. Knowledgeable
                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it

                           ===== Strengths =====

- timely problem
- basic set up interesting

                          ===== Weaknesses =====

- falls short of promised generality
 - fault tolerance analysis is too basic

                      ===== Comments to authors =====

The paper introduces Methane, a tool to synthesize correct-by-construction network role templates. The tool takes as input three things: high level description of the network topology, the routing policy, and fault tolerance requirements. Then Methane generates role templates if the fault tolerance policy can be met.

I liked the idea of the paper and the synthesis problem is a very timely one. However, I think the paper fall short of its promises in the introduction and hence I cannot really recommend it to be accepted.

Major comments
- One of the contributions claimed in the end of the introduction is "new topology abstractions". After reading the paper I am still not quite sure what you mean by this.
- Your main theoretical result (Theorem 7.2) applies only to a network running the BGP protocol. Is this correct?
- I found the proof in the appendix almost impossible to follow. It needs to first be explained at a high level (enumerating all the auxiliary lemmas) and you should describe concretely where the hard parts are. As it stands it looks like a routine induction proof (which is long, messy and poorly typeset in LaTeX).
- I was expecting (since you are doing fault tolerance analysis) that you would compile your language into a probabilistic automaton rather than the usual DFA. Can you comment?
- In the current version, your notion of fault tolerance and fault tolerance analysis is quite limited. Namely, you can only say whether all concrete instances will be able to remain functional up to k link failure. Is this really enough in practical contexts? Would one not want a finer analysis?
- In particular, I would expect a sort of threshold analysis. And that would mean that you might be able to generate more templates than you currently can (with associated QoS guarantees).

All in all, I think the main problem of the paper is that it starts with a promise of generality that as the reader makes his way through disappears. I cannot completely see the added value of the abstract topology analysis and the claim on fault tolerance if then properties are proved for a very concrete network.

Minor comments
- Compilation (I guess) could be improved using work by Smolka et al (done in the context of NetKAT).
- the constraints displayed on Fig 7 made me wonder if you could not use a constraint solver or similar methods to help in your algorithm.
- The mathematical notation chosen is somewhat confusing. Eg you use (-)^A to name the abstract graph, etc, but since you re also talking about homomorphisms I thought for a while this was a real exponential. Others might be confused too.
- on page 4 you say there will be a one to one correspondence between the concrete and abstract nodes. are you sure you mean one to one? I would expect to have less abstract nodes...

===========================================================================
                           PLDI '17 Review #187D
---------------------------------------------------------------------------
   Paper #187: Network Configuration Synthesis with Abstract Topologies
---------------------------------------------------------------------------

                 Reviewer expertise: Y. Knowledgeable
                      Overall merit: B. OK paper, but I will not champion
                                        it

                           ===== Strengths =====

+ Interesting high-level objective
+ Good experimental results

                          ===== Weaknesses =====

- The description of the template generation process -- a central contribution of the paper -- is hard to follow and tied to a particular example.

                      ===== Comments to authors =====

Summary:

The paper presents a method for synthesis of provably-correct "role" templates networks. A role is as an abstraction of a device functionality that can be served by one or more devices. in current practice, engineers hand-write "configuration templates" for each role in the network.  Concrete network configurations are obtained by instantiating these templates with concrete parameters, based on the topology of the network. The paper argues that the these templates are challenging to construct and error-prone. Its solution is to automatically synthesize these templates for the different roles given a description of the topology in terms of roles, and requirements such as the routing policy or fault-tolerance requirements of the network. It is guaranteed that every configuration obtained by concretizing the profile of synthesized templates will satisfy these requirements. The system is evaluated on a range of backbone and data center networks.

Evaluation:

The high-level goals of the paper are appealing.  The paper makes a convincing case that the manual design of roles is brittle and difficult, and therefore a natural target for synthesis.

As for the technical approach, the idea of defining abstract topologies in terms of roles is natural (even if some additional constraints are needed to make abstract topologies carry enough information). The idea of using a product of the policy and the abstract topology as an intermediate representation is also reasonable.

However, the template generation component is disappointing. This description of this process in the paper primarily speaks of the particular example of the BGP protocol. This  makes it hard to tell the scope of the method. Given that the paper positions itself as a general method for configuration synthesis, this is not adequate.

In many other circumstances, I would have requested the authors to come up with a more abstract description of the algorithm in the final version of the paper. The problem in this case is that I don't even see what that more abstract algorithm would be. It seems to me that the method here may only be for a specific application. If that is so, the text in the early parts of the paper needs to be significantly rewritten.

The experimental results are impressive. Specifically, the method seems to offer substantially better performance than the existing Propane system. However, the paper doesn't discuss the effort required in defining the specification (in particular the abstract topology), and this is a flaw.


===========================================================================
             Response by Ryan Beckett <rbeckett@princeton.edu>
   Paper #187: Network Configuration Synthesis with Abstract Topologies
---------------------------------------------------------------------------
Thank you to the reviewers for your thoughtful comments and questions. The most common concerns were: (1) the approach is specific to the BGP routing protocol, (2) the paper was lacking discussion on how difficult it is to define abstractions and whether an operator could reasonably be expected to do so, and (3) the template generation and incrementality sections need more explanation since they are central to the paper. We respond to each of these in turn:

(1) The approach is specific to the BGP routing protocol

In the paper, the actual template generation phase does focus on the BGP routing protocol. We did so for several pragmatic reasons:  i) BGP is an industry standard that is widely used both internally (e.g., in data centers) as well as externally to link together multiple networks, ii) it allows for rich, policy-based routing and can therefore implement many routing policies that other protocols can not, and iii) for the sake of building a complete, end-to-end tool, we build on top of the Propane synthesis tool, which targets BGP configurations.

The template generation process is specifically for BGP protocol. However, the new topology abstractions, the abstract product graph, and the fault tolerance analysis are fully general and do not depend on any particular routing protocol. For example, there is no reason why one could not instead translate from the abstract product graph to configurations for the ISIS link-state protocol. ISIS also supports policy-based filtering and could potentially implement neighbor preferences using link weights rather than explicit preferences. Further, Theorem 7.2 is purely a substitution proof and does not depend on the underlying semantics of BGP. We can sharpen these distinctions in the paper.

(2) Discuss how hard is it to define abstractions and whether an operator be expected to do so

On the difficulty of operators providing an abstract topology as input -- typically the input already exists as structured data that is passed on from the network designers to on-site administrators that wire things up. For example, there will be requirements of the form: “each ToR should connect to 16 aggregation switches in the same pod”. The edge and node multiplicity-based constraints we present in the paper were, in part, motivated by conversations with operators about their preferred mode of thinking about the network abstractly.  Also, many of the different types of networks we encoded as abstractions in the evaluation required only very basic annotations. We can expand on this further in the paper.

(3) Template generation and incrementality need more explanation

Due to space restrictions, we had to make difficult decisions about what to include in the paper and what to move to the appendix. With more space in a final version (often the program chair will grant 2 extra pages), we can move much of the explanation of template generation and network evolution from the appendix into the main body of the paper and refine it. In particular, we will explain more clearly exactly what the incrementality guarantees are and when they hold.

We respond to other review comments one-by-one below (this extends past the word limit). Reviewers can scan for questions relevant to them.

# Reviewer 187A

>One of the contributions listed by the authors is the notion of abstract topologies. Topology
>abstractions for BGP were also defined in the following paper:
>Adi Sosnovich, Orna Grumberg, Gabi Nakibly: Analyzing Internet Routing Security Using
>Model Checking. LPAR 2015: 112-129

Thanks for the pointer! We will look into this further and compare with our work.

>Providing an abstract topology that is ``precise'' enough is tedious. The user has to provide
>invariants on the structure of the underlying concrete topology. Is this a reasonable
>requirement from a network operator?

Please see our explanation above.

>Template generation: if I understand correctly, you add tags to the BGP announcements. Is this
>acceptable by network operators? Doesn't it affect the protocol? It seems that you in fact
>change the protocol (or refine it). In addition, this raises a question regarding the generality of
>the approach. Can a variant be used with different protocols?

We do not change the protocol. Tags are specified as a part of the device’s low-level routing configuration and are already understood by the protocol [RFC 1997]. The configurations generated by Methane will run on unmodified devices. It is also very common for BGP policies in production already to use tags. Operators typically manually configure such tags. A similar idea could be realized in other protocols (e.g., with the ISIS protocol and route tags)

>The part about instantiating the templates (explained in page 3) is under-explained in the
>paper. A lot of it is deferred to the appendix (as mentioned after theorem 7.2). I believe a better
>explanation should be included in the paper.

Sorry for the confusion. With more space in a final version, we can move more content from the appendix into the main paper and clarify the section.

>Regarding the paragraph on "incrementality" -- please clarify whether these optimizations are
>manual (my understanding is that they are).

These optimizations are automatic (not manual). When the tool generates configuration templates, it makes sure to always use tag-based filtering rather than prefix-based filtering. This guarantees that changes in the topology can never result in non-local changes to the configurations. If an operator adds nodes and/or edges to the network, they just need to run the tool again and unaffected routers will end up with identical configurations. We will clarify this point.

>Implementation "inference rules... depend only on the topology" -- then why didn't you present
>them this way? This is confusing since earlier you explained that it is important to perform the
>inference on the product graph that also includes routing information.

Thanks for pointing this out, we will clarify. The inference rules depend only on the topology locations (not the automaton states). However, the inference rules apply only to directed edges, which is how they take into account the policy-based routing defined by the product graph.

# Reviewer 187B

>As far as I can tell, Methane fault-tolerance policies and inference rules are restricted to link
>failures, not node failures which, although less likely, do still happen quite often in large-scale
>networks. Do the inference rules and facts generalize to node-disjointness? If so how, if not
>why?

Currently, Methane fault-tolerance policies and inference rules are indeed restricted to link failures. We focused on link failures because, as you mention, they are more common in large-scale networks and companies will take down links for maintenance all the time.  We have investigated inference rules for node failures to some degree and in most cases, the situation is actually much simpler than for link failures.   We believe it should be quite possible to extend the analysis to node failures.

>How far away from the real value can the lower bound computed by the inference rules be?
>Can you bound it somehow? In general, I think it would help the reader to illustrate a situation
>in which Methane’s inferred lower-bound is conservative instead of being precise, e.g. could be
>the case that you mention in Section 9.1.

>How far off was Methane when it generated conservative bound instead of precise ones? The
>Evaluation only gives binary information right now. Please add these numbers to the paper.
>Also, and this goes back to my point above, the fact that you start to have conservative results
>instead of precise ones when switching from valley-free routing to shortest-path routing makes
>the reader wonder how would the result change should you use more complex routing policies.
>This goes back to my point above > Please comment on what Methane precision depends on.

In general, we found that the results are mixed. We found that, at times the fault tolerance analysis will only be slightly imprecise, and at other times it will produce a very conservative answer. We can try to add an example of a topology where this can happen (e.g., one of the recursive topologies). We can also include more fine-grained detail about how imprecise the analysis is in a revised version of the evaluation section. While we do not provide any lower bound on the fault tolerance, it is worth noting that a user can always provide more information about fault-tolerance to Methane in the form of mincut annotations at the cost of generality.

>I think the paper is quite thin on incrementality. While the intuition presented in Section 7 is
>nice (I see a parallel with source routing in which the rules in the core of the network are fixed
>and where the tagging is moved to the edge), it seems hard to believe that prefix template
>variable is the only piece that requires to be changed upon change in the concrete topology. If
>that's the case, it requires more backing on why it is the case.

Given more space, we will expand on and better explain the incrementality section. The intuition for why the prefix template variable is the only piece that needs to be changed is because the abstract policy and abstract topology both remain fixed. Any additional nodes added to the topology must fall into an existing role and will be treated the same as others in its role by every other router. However, adding a router can introduce new prefixes to the policy and can require non-local changes to prefix-based filters elsewhere in the network, which the source-based tagging mechanism solves.

>Another point regarding incrementality. Would you also have it considering other protocols? In
>particular, my intuition is that incrementality is possible in your case because you’re
>considering neighbor & policy-based configurations. This wouldn’t be true for say, link-state
>protocols where I would expect that more network-wide changes are required to implement a
>requirement (e.g., weight changes in multiple locations).

Your intuition about incrementality is right. In particular, the main reason for the incrementality guarantee is because each router only makes decisions based based on i) its immediate neighbor, ii) the state of the automaton tagged to an advertisement, and iii) the presence of a finite number of source tags. Since the abstract topology and policy do not change when a new router is added or removed, the set of automaton states and source tags will remain the same. Thus only routers connected to a new neighbor will be affected. It may be the case that this does not hold in general for link-state protocols.

>AFAIU, you used a fat tree topology for the ISP topology, which is not so realistic IMHO. Would >the results be any different should you use a (much less regular) topology from topology-zoo or >RocketFuel instead? Please justify why/why not?

We use fat tree topologies only for the data center experiments. For the backbone networks we study, we use a different topology more similar to those found in the topology-zoo. The abstraction we use for these networks resembles that of the one big switch abstraction from software-defined networking, where the border routers are all abstracted into a single node, and the internal topology is abstracted into a separate abstract node.

>Related work on the connectivity guarantees provided by policy-based routing protocols exists, >in particular “A Theory for the Connectivity Discovered by Routing Protocols” (TON 2012) by >Sobrinho and Quelhas. In this paper, the authors provide a “polynomial time algorithm to >compute the minimum number of links whose failure leaves a route-vector protocol without a >communication path from one given node to another”. As it relates to Methane reasoning on >policy-compliant connectivity (arguably on abstract, not concrete topologies), I would still cite it >and distinguish from it.

Thanks for the reference, we will look at this paper and add a comparison with our own.

# Reviewer 187C

>One of the contributions claimed in the end of the introduction is "new topology abstractions".
>After reading the paper I am still not quite sure what you mean by this.
>Your main theoretical result (Theorem 7.2) applies only to a network running the BGP protocol.
>Is this correct?

The new topology abstractions refers to the combination of the topology graph homomorphism, edge/node multiplicities in the form of SMT constraints, and hierarchical nesting of structure through pods. The topology abstractions, the policy intermediate representation in the abstract product graph, and the fault tolerance analysis all do not depend on BGP, however Theorem 7.2 is for a network running BGP.

>I found the proof in the appendix almost impossible to follow. It needs to first be explained at a
>high level (enumerating all the auxiliary lemmas) and you should describe concretely where
>the hard parts are. As it stands it looks like a routine induction proof (which is long, messy and
>poorly typeset in LaTeX).

Sorry for the lack of clarity. We will reformat and clean up the proof in the appendix.

>I was expecting (since you are doing fault tolerance analysis) that you would compile your
>language into a probabilistic automaton rather than the usual DFA. Can you comment?
>In the current version, your notion of fault tolerance and fault tolerance analysis is quite limited.
>Namely, you can only say whether all concrete instances will be able to remain functional up to
>k link failure. Is this really enough in practical contexts? Would one not want a finer analysis?
>In particular, I would expect a sort of threshold analysis. And that would mean that you might
>be able to generate more templates than you currently can (with associated QoS guarantees).

The way operators typically check their policies for robustness today is by simulating all 1 (and maybe 2) link failure combinations to try to find a worst-case scenario. For the purposes of this paper, we were interested in providing a worst-case lower bound on fault-tolerance rather than average-case analysis. Worst-case bounds are still useful to identify failure scenarios that lead to poor interactions with routing policy (e.g., the aggregation-induced black holes described in the paper). To reason about expected fault tolerance (e.g., for random networks), probabilistic automaton would likely be more a appropriate approach.

>All in all, I think the main problem of the paper is that it starts with a promise of generality that
>as the reader makes his way through disappears. I cannot completely see the added value of
>the abstract topology analysis and the claim on fault tolerance if then properties are proved for
>a very concrete network.

Properties proved for the abstract network are true for every concrete instantiation. The main value, in our minds, of the abstract topology analysis is that one does not have to rethink their topology and routing policy every time the network changes. This lets the operator design the network once and be assured that the network will continue to function as expected even as the topology changes.


# Reviewer 187D

>However, the template generation component is disappointing. This description of this process
>in the paper primarily speaks of the particular example of the BGP protocol. This makes it hard
>to tell the scope of the method. Given that the paper positions itself as a general method for
>configuration synthesis, this is not adequate.

Thanks for pointing this out. Many components of the paper are independent of any particular protocol, but the translation at the bottom is specific to BGP.  Fortunately, BGP is the protocol used by many large companies in their data centers.  In addition, please see our comments above.

>In many other circumstances, I would have requested the authors to come up with a more
>abstract description of the algorithm in the final version of the paper. The problem in this case
>is that I don't even see what that more abstract algorithm would be. It seems to me that the
>method here may only be for a specific application. If that is so, the text in the early parts of the
>paper needs to be significantly rewritten.

The language, abstract intermediate representation, and fault tolerance analysis are all independent of any particular protocol such as BGP. We ended up using BGP for the many reasons we list above. We can more clearly separate these ideas in the paper.

>The experimental results are impressive. Specifically, the method seems to offer substantially
>better performance than the existing Propane system. However, the paper doesn't discuss the
>effort required in defining the specification (in particular the abstract topology), and this is a
>flaw.

Please see our comments above.
